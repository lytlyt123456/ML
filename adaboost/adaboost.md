# （一）AdaBoost算法

AdaBoost算法的思想是集成多个弱分类器的优势，组成一个更强大的分类器。弱分类器通常采用决策树实现。

AdaBoost算法为每个训练样本赋予一个权重 $\left\{ \omega_{i} \right\}_{i = 1}^{N}$。起初，每个样本的权重均被初始化为 $\frac{1}{N}$，即 $\omega_{i} = \frac{1}{N},i \in \{ 1,2,\ldots,N\}$。

我们共训练 $T$ 个弱分类器，其中 $T$ 为超参数。在第 $t(t \in \{ 1,2,\ldots,T\})$ 轮训练中，利用上一轮训练更新后的样本权重训练第 $t$ 个弱分类器，第1轮训练利用初始化的样本权重。训练完毕后，利用训练数据集计算该弱分类器的分类错误率 $e_{t}$：

$$e_{t} = \sum_{{\widehat{y}}_{i}^{(t)} \neq y_{i}}^{}\omega_{i}$$

令

$$\alpha_{t} = \frac{1}{2}\ln\frac{1 - e_{t}}{e_{t}}$$

$\alpha_{t}$ 在 $e_{t} \in (0,1)$ 上单调递减，且：

$$e_{t} \rightarrow 0,\alpha_{t} \rightarrow + \infty$$

$$e_{t} = \frac{1}{2},\alpha_{t} = 0$$

$$e_{t} \rightarrow 1,\alpha_{t} \rightarrow - \infty$$

之后利用 $\alpha_{t}$ 更新样本权重：

$$\omega_{i} \leftarrow \left\{ \begin{array}{r}
\omega_{i}e^{- \alpha_{t}},{\widehat{y}}_{i}^{(t)} = y_{i} \\
\omega_{i}e^{\alpha_{t}},{\widehat{y}}_{i}^{(t)} \neq y_{i}
\end{array} \right.\ $$

再对样本权重归一化：

$$\omega_{i} \leftarrow \frac{\omega_{i}}{\sum_{j = 1}^{N}\omega_{j}}$$

然后按照同样的方法训练下一个分类器。

训练得到的权重 $\alpha_{t}$ 为每个分类器的权重。采用如下方法进行决策：

$${\widehat{y}}_{i} = 
\begin{cases}
1, & \sum_{t = 1}^{T}{\alpha_{t}{\widehat{y}}_{i}^{(t)}} > 0 \\
-1, & \sum_{t = 1}^{T}{\alpha_{t}{\widehat{y}}_{i}^{(t)}} < 0
\end{cases}
$$

1、为什么每个分类器的权重用 $\alpha_{t} = \frac{1}{2}\ln\frac{1 - e_{t}}{e_{t}}$ 计算？

当 $e_{t} < \frac{1}{2}$ 时，分类器对大部分样本的决策都是正确的，此时 $\alpha_{t} > 0$，而且决策的错误率 $e_{t}$ 越小，该分类器就越可靠，其在决策时占的权重就越大。当 $e_{t} = \frac{1}{2}$ 时，分类器做出正确决策的样本数量和分类器做出错误决策的样本数量相等，相当于"瞎猜"，因此该分类器没有任何可靠性，其权重 $\alpha_{t} = 0$。当 $e_{t} > \frac{1}{2}$ 时，${\widehat{y}}_{i}^{(t)}$ 中分类错误的样本数量大于分类正确的样本数量，我们可以反过来利用 $- {\widehat{y}}_{i}^{(t)}$ 作为分类器的决策。此时利用原决策方式决策的正确率为利用新决策方式决策的错误率，$e_{t}' = 1 - e_{t}$。此时 $e_{t}' < \frac{1}{2}$，分类器权重 $\alpha_{t}' = \frac{1}{2}\ln\frac{1 - e_{t}'}{e_{t}'} = \frac{1}{2}\ln\frac{e_{t}}{1 - e_{t}} = - \frac{1}{2}\ln\frac{1 - e_{t}}{e_{t}} = - \alpha_{t}$。分类器的决策与其权重相乘的结果 $\alpha_{t}' \bullet \left( - {\widehat{y}}_{i}^{(t)} \right) = - \alpha_{t} \bullet \left( - {\widehat{y}}_{i}^{(t)} \right) = \alpha_{t}{\widehat{y}}_{i}^{(t)}$。形式上与 $e_{t} < \frac{1}{2}$ 时的加权决策相同。因此我们可以统一使用公式 $\alpha_{t} = \frac{1}{2}\ln\frac{1 - e_{t}}{e_{t}}$ 计算每个分类器的权重。

2、为什么每个样本的权重用
$
\omega_{i} \leftarrow 
\begin{cases}
\omega_{i}e^{- \alpha_{t}}, & {\widehat{y}}_{i}^{(t)} = y_{i} \\
\omega_{i}e^{\alpha_{t}}, & {\widehat{y}}_{i}^{(t)} \neq y_{i}
\end{cases}
$
更新？

当 $e_{t} < \frac{1}{2}$ 时，$\alpha_{t} > 0$，$e^{- \alpha_{t}} < 1$，$e^{\alpha_{t}} > 1$，因此分类正确的样本权重减少，分类错误的样本权重增加。由于分类错误的样本是当前分类器的"知识盲区"，增大其权重可以使得下一个分类器更加关注这些样本，从而尽可能对这些样本实现正确分类，有效弥补前一个分类器的知识缺失。

当 $e_{t} > \frac{1}{2}$ 时，$\alpha_{t} < 0$，$e^{- \alpha_{t}} > 1$，$e^{\alpha_{t}} < 1$，因此原分类器分类正确的样本权重增加，原分类器分类错误的样本权重减少。但由于在错误率超过50%时，我们采用原分类器预测值的相反值作为分类结果，所以最终仍然是增大错误样本的权重、减少正确样本的权重。

# （二）Haar特征提取

在传统机器学习中，通常需要人为从图像、文本、音频等非结构化数据中提取结构化特征。Haar特征是一类用于捕捉图像不同区域明暗变化信息的特征，常用于人脸检测。其包含五种子类别：

## 1、水平双矩形特征

对于图像中的每个宽度为偶数个像素的矩形，将其等分为左右两个大小和形状完全相同的矩形。左侧矩形的像素值之和 $S_{l}$ 代表左侧矩形的明暗程度，右侧矩形的像素值之和 $S_{r}$ 代表右侧矩形的明暗程度。$\mathrm{\Delta}S = S_{l} - S_{r}$ 代表从左侧矩形到右侧矩形的明暗变化程度。$\mathrm{\Delta}S$ 即为该水平双矩形的特征值。

## 2、垂直双矩形特征

对于图像中的每个高度为偶数个像素的矩形，将其等分为上下两个大小和形状完全相同的矩形。上侧矩形的像素值之和 $S_{t}$ 代表上侧矩形的明暗程度，下侧矩形的像素值之和 $S_{b}$ 代表下侧矩形的明暗程度。$\mathrm{\Delta}S = S_{t} - S_{b}$ 代表从上侧矩形到下侧矩形的明暗变化程度。$\mathrm{\Delta}S$ 为该垂直双矩形的特征值。

## 3、水平三矩形特征

对于图像中每个宽度为3的倍数的矩形，将其等分为左中右3个大小和形状完全相同的矩形。左侧矩形的像素值之和 $S_{l}$ 代表左侧矩形的明暗程度，右侧矩形的像素值之和 $S_{r}$ 代表右侧矩形的明暗程度，中间的矩形的像素值之和 $S_{m}$ 代表中间矩形的明暗程度。$\mathrm{\Delta}S = S_{l} + S_{r} - S_{m}$ 代表该水平三矩形左右两侧与中间的明暗对比度（可以捕捉中间比两边亮、中间比两边暗等特征）。$\mathrm{\Delta}S$ 即为该水平三矩形的特征值。

## 4、垂直三矩形特征

对于图像中每个高度为3的倍数的矩形，将其等分为上中下3个大小和形状完全相同的矩形。上侧矩形的像素值之和 $S_{t}$ 代表上侧矩形的明暗程度，下侧矩形的像素值之和 $S_{b}$ 代表下侧矩形的明暗程度，中间的矩形的像素值之和 $S_{m}$ 代表中间矩形的明暗程度。$\mathrm{\Delta}S = S_{t} + S_{b} - S_{m}$ 代表该垂直三矩形上下两侧与中间的明暗对比度（可以捕捉上下比中间亮、上下比中间暗等特征，如鼻子中间上凸的部分在光照下会比两侧下凹的部分更亮）。$\mathrm{\Delta}S$ 即为该垂直三矩形的特征值。

## 5、四矩形特征

对于图像中每个高度和宽度均为偶数个像素的矩形，将其等分为左上、左下、右上、右下4个大小和形状完全相同的矩形。左上矩形、左下矩形、右上矩形、右下矩形的像素值之和 $S_{lt}$、$S_{lb}$、$S_{rt}$、$S_{rb}$ 分别代表这4个矩形的明暗程度。$\mathrm{\Delta}S = (S_{lt} + S_{rb}) - (S_{lb} + S_{rt})$ 代表两个对角线的明暗对比度（可以捕捉倾斜的明暗过渡，如鼻梁两侧的脸颊部分）。$\mathrm{\Delta}S$ 即为该四矩形的特征值。

从图像中提取若干Haar特征，形成一个特征向量，用于训练机器学习模型。

其中，计算图像中某个矩形区域所包含的像素值之和，可以通过积分图在常数时间内计算。一个像素值在积分图中对应的值即为行数和列数都不超过该像素的所有像素值之和，上侧和左侧用0值填充，以统一图像边缘和内部计算像素值之和的操作。示例如下：

设图像包含以下像素值：

$$\left\lbrack \begin{array}{r}
1 \\
4 \\
7
\end{array}\ \ \ \ \begin{array}{r}
2 \\
5 \\
8
\end{array}\ \ \ \ \begin{array}{r}
3 \\
6 \\
9
\end{array} \right\rbrack$$

其积分图为：

$$\left\lbrack \begin{array}{r}
0 \\
0 \\
0 \\
0
\end{array}\ \ \ \ \begin{array}{r}
0 \\
1 \\
5 \\
12
\end{array}\ \ \ \ \begin{array}{r}
0 \\
3 \\
12 \\
27
\end{array}\ \ \ \ \begin{array}{r}
0 \\
6 \\
21 \\
45
\end{array} \right\rbrack$$

设原图为 $I$，积分图为 $I_{s}$。则 $I\lbrack i..j,k..l\rbrack$ 这个矩形区域所有像素值之和就可以通过下面的公式求得：

$$sum\left( I\lbrack i...j,k...l\rbrack \right)$$

$$= I_{s}\lbrack j + 1,l + 1\rbrack - I_{s}\lbrack i,l + 1\rbrack - I_{s}\lbrack j + 1,k\rbrack + I_{s}\lbrack i,k\rbrack$$